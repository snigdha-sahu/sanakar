{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16dcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735bde5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>97.58</td>\n",
       "      <td>546.08</td>\n",
       "      <td>28</td>\n",
       "      <td>97200</td>\n",
       "      <td>69.75</td>\n",
       "      <td>15.33</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>324.50</td>\n",
       "      <td>127.28</td>\n",
       "      <td>84.85</td>\n",
       "      <td>73.48</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0</td>\n",
       "      <td>4556.99</td>\n",
       "      <td>66.09</td>\n",
       "      <td>6.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>8</td>\n",
       "      <td>84</td>\n",
       "      <td>273.61</td>\n",
       "      <td>1167.85</td>\n",
       "      <td>22</td>\n",
       "      <td>118125</td>\n",
       "      <td>23.11</td>\n",
       "      <td>6.96</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>403.89</td>\n",
       "      <td>320.40</td>\n",
       "      <td>236.27</td>\n",
       "      <td>55.93</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0</td>\n",
       "      <td>13771.48</td>\n",
       "      <td>36.18</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>87</td>\n",
       "      <td>125</td>\n",
       "      <td>1785.22</td>\n",
       "      <td>1487.77</td>\n",
       "      <td>3</td>\n",
       "      <td>312500</td>\n",
       "      <td>38.87</td>\n",
       "      <td>10.31</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>901.39</td>\n",
       "      <td>500.00</td>\n",
       "      <td>288.89</td>\n",
       "      <td>135.64</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0</td>\n",
       "      <td>4736.75</td>\n",
       "      <td>66.31</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>52.92</td>\n",
       "      <td>580.92</td>\n",
       "      <td>24</td>\n",
       "      <td>105300</td>\n",
       "      <td>61.69</td>\n",
       "      <td>6.99</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>484.66</td>\n",
       "      <td>180.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>49.30</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0</td>\n",
       "      <td>3414.04</td>\n",
       "      <td>66.12</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>122</td>\n",
       "      <td>91</td>\n",
       "      <td>1413.71</td>\n",
       "      <td>891.77</td>\n",
       "      <td>25</td>\n",
       "      <td>227500</td>\n",
       "      <td>35.87</td>\n",
       "      <td>9.61</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>782.62</td>\n",
       "      <td>492.44</td>\n",
       "      <td>250.29</td>\n",
       "      <td>116.19</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0</td>\n",
       "      <td>4943.07</td>\n",
       "      <td>65.93</td>\n",
       "      <td>7.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "      <td>36.05</td>\n",
       "      <td>427.84</td>\n",
       "      <td>126</td>\n",
       "      <td>153900</td>\n",
       "      <td>59.53</td>\n",
       "      <td>12.15</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>324.50</td>\n",
       "      <td>244.38</td>\n",
       "      <td>97.32</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "      <td>2355.99</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>95</td>\n",
       "      <td>175</td>\n",
       "      <td>1647.32</td>\n",
       "      <td>1728.44</td>\n",
       "      <td>94</td>\n",
       "      <td>437500</td>\n",
       "      <td>39.12</td>\n",
       "      <td>6.59</td>\n",
       "      <td>4480.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1353.70</td>\n",
       "      <td>550.00</td>\n",
       "      <td>300.09</td>\n",
       "      <td>138.81</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0</td>\n",
       "      <td>4386.19</td>\n",
       "      <td>66.41</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>76</td>\n",
       "      <td>11</td>\n",
       "      <td>145.27</td>\n",
       "      <td>576.27</td>\n",
       "      <td>81</td>\n",
       "      <td>89100</td>\n",
       "      <td>57.82</td>\n",
       "      <td>12.07</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>270.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.95</td>\n",
       "      <td>66.15</td>\n",
       "      <td>6.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>147.45</td>\n",
       "      <td>561.18</td>\n",
       "      <td>120</td>\n",
       "      <td>89100</td>\n",
       "      <td>63.45</td>\n",
       "      <td>19.61</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>127.28</td>\n",
       "      <td>63.64</td>\n",
       "      <td>73.48</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "      <td>5280.98</td>\n",
       "      <td>66.13</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>284.64</td>\n",
       "      <td>648.92</td>\n",
       "      <td>114</td>\n",
       "      <td>291600</td>\n",
       "      <td>50.06</td>\n",
       "      <td>15.48</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>603.74</td>\n",
       "      <td>569.21</td>\n",
       "      <td>301.42</td>\n",
       "      <td>233.65</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12998.43</td>\n",
       "      <td>66.30</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f_1  f_2      f_3      f_4  f_5     f_6    f_7    f_8     f_9  f_10  ...  \\\n",
       "706   59   12    97.58   546.08   28   97200  69.75  15.33   884.0  0.22  ...   \n",
       "440    8   84   273.61  1167.85   22  118125  23.11   6.96  1130.0  0.30  ...   \n",
       "97    87  125  1785.22  1487.77    3  312500  38.87  10.31  2740.0  0.27  ...   \n",
       "681   34   13    52.92   580.92   24  105300  61.69   6.99   847.0  0.11  ...   \n",
       "390  122   91  1413.71   891.77   25  227500  35.87   9.61  2130.0  0.27  ...   \n",
       "884  152   19    36.05   427.84  126  153900  59.53  12.15  1281.0  0.20  ...   \n",
       "105   95  175  1647.32  1728.44   94  437500  39.12   6.59  4480.0  0.17  ...   \n",
       "644   76   11   145.27   576.27   81   89100  57.82  12.07   831.0  0.21  ...   \n",
       "636   68   11   147.45   561.18  120   89100  63.45  19.61   937.0  0.31  ...   \n",
       "599   31   36   284.64   648.92  114  291600  50.06  15.48  2038.0  0.31  ...   \n",
       "\n",
       "        f_41    f_42    f_43    f_44  f_45  f_46      f_47   f_48   f_49  \\\n",
       "706   324.50  127.28   84.85   73.48  3.82     0   4556.99  66.09   6.22   \n",
       "440   403.89  320.40  236.27   55.93  1.71     0  13771.48  36.18  15.02   \n",
       "97    901.39  500.00  288.89  135.64  3.12     0   4736.75  66.31   8.01   \n",
       "681   484.66  180.00  126.00   49.30  3.85     0   3414.04  66.12   6.05   \n",
       "390   782.62  492.44  250.29  116.19  3.13     0   4943.07  65.93   7.71   \n",
       "884   402.49  324.50  244.38   97.32  1.65     0   2355.99  65.91   6.15   \n",
       "105  1353.70  550.00  300.09  138.81  4.51     0   4386.19  66.41   7.76   \n",
       "644   270.00  180.00  150.00   51.96  1.80     0   5097.95  66.15   6.34   \n",
       "636   402.49  127.28   63.64   73.48  6.32     0   5280.98  66.13   6.37   \n",
       "599   603.74  569.21  301.42  233.65  2.00     0  12998.43  66.30   6.71   \n",
       "\n",
       "     target  \n",
       "706       0  \n",
       "440       1  \n",
       "97        0  \n",
       "681       0  \n",
       "390       0  \n",
       "884       0  \n",
       "105       0  \n",
       "644       0  \n",
       "636       0  \n",
       "599       0  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('oil_spill (3).csv')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1293d02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995f9b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>9.370000e+02</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>937.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.588047</td>\n",
       "      <td>332.842049</td>\n",
       "      <td>698.707086</td>\n",
       "      <td>870.992209</td>\n",
       "      <td>84.121665</td>\n",
       "      <td>7.696964e+05</td>\n",
       "      <td>43.242721</td>\n",
       "      <td>9.127887</td>\n",
       "      <td>3940.712914</td>\n",
       "      <td>0.221003</td>\n",
       "      <td>...</td>\n",
       "      <td>933.928677</td>\n",
       "      <td>427.565582</td>\n",
       "      <td>255.435902</td>\n",
       "      <td>106.112519</td>\n",
       "      <td>5.014002</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>7985.718004</td>\n",
       "      <td>61.694386</td>\n",
       "      <td>8.119723</td>\n",
       "      <td>0.043757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>64.976730</td>\n",
       "      <td>1931.938570</td>\n",
       "      <td>599.965577</td>\n",
       "      <td>522.799325</td>\n",
       "      <td>45.361771</td>\n",
       "      <td>3.831151e+06</td>\n",
       "      <td>12.718404</td>\n",
       "      <td>3.588878</td>\n",
       "      <td>8167.427625</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.681331</td>\n",
       "      <td>715.391648</td>\n",
       "      <td>534.306194</td>\n",
       "      <td>135.617708</td>\n",
       "      <td>5.029151</td>\n",
       "      <td>0.334344</td>\n",
       "      <td>6854.504915</td>\n",
       "      <td>10.412807</td>\n",
       "      <td>2.908895</td>\n",
       "      <td>0.204662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.031200e+04</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2051.500000</td>\n",
       "      <td>35.950000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>85.270000</td>\n",
       "      <td>444.200000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.250000e+05</td>\n",
       "      <td>33.650000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1371.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>90.800000</td>\n",
       "      <td>50.120000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3760.570000</td>\n",
       "      <td>65.720000</td>\n",
       "      <td>6.340000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>704.370000</td>\n",
       "      <td>761.280000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.863000e+05</td>\n",
       "      <td>39.970000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>2090.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>685.420000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>161.650000</td>\n",
       "      <td>73.850000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5509.430000</td>\n",
       "      <td>65.930000</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1223.480000</td>\n",
       "      <td>1260.370000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>3.304680e+05</td>\n",
       "      <td>52.420000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>3435.000000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>...</td>\n",
       "      <td>1053.420000</td>\n",
       "      <td>460.980000</td>\n",
       "      <td>265.510000</td>\n",
       "      <td>125.810000</td>\n",
       "      <td>6.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9521.930000</td>\n",
       "      <td>66.130000</td>\n",
       "      <td>7.840000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>352.000000</td>\n",
       "      <td>32389.000000</td>\n",
       "      <td>1893.080000</td>\n",
       "      <td>2724.570000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>7.131500e+07</td>\n",
       "      <td>82.640000</td>\n",
       "      <td>24.690000</td>\n",
       "      <td>160740.000000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>...</td>\n",
       "      <td>11949.330000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>9593.480000</td>\n",
       "      <td>1748.130000</td>\n",
       "      <td>76.630000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55128.460000</td>\n",
       "      <td>66.450000</td>\n",
       "      <td>15.440000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f_1           f_2          f_3          f_4         f_5  \\\n",
       "count  937.000000    937.000000   937.000000   937.000000  937.000000   \n",
       "mean    81.588047    332.842049   698.707086   870.992209   84.121665   \n",
       "std     64.976730   1931.938570   599.965577   522.799325   45.361771   \n",
       "min      1.000000     10.000000     1.920000     1.000000    0.000000   \n",
       "25%     31.000000     20.000000    85.270000   444.200000   54.000000   \n",
       "50%     64.000000     65.000000   704.370000   761.280000   73.000000   \n",
       "75%    124.000000    132.000000  1223.480000  1260.370000  117.000000   \n",
       "max    352.000000  32389.000000  1893.080000  2724.570000  180.000000   \n",
       "\n",
       "                f_6         f_7         f_8            f_9        f_10  ...  \\\n",
       "count  9.370000e+02  937.000000  937.000000     937.000000  937.000000  ...   \n",
       "mean   7.696964e+05   43.242721    9.127887    3940.712914    0.221003  ...   \n",
       "std    3.831151e+06   12.718404    3.588878    8167.427625    0.090316  ...   \n",
       "min    7.031200e+04   21.240000    0.830000     667.000000    0.020000  ...   \n",
       "25%    1.250000e+05   33.650000    6.750000    1371.000000    0.160000  ...   \n",
       "50%    1.863000e+05   39.970000    8.200000    2090.000000    0.200000  ...   \n",
       "75%    3.304680e+05   52.420000   10.760000    3435.000000    0.260000  ...   \n",
       "max    7.131500e+07   82.640000   24.690000  160740.000000    0.740000  ...   \n",
       "\n",
       "               f_41          f_42         f_43         f_44        f_45  \\\n",
       "count    937.000000    937.000000   937.000000   937.000000  937.000000   \n",
       "mean     933.928677    427.565582   255.435902   106.112519    5.014002   \n",
       "std     1001.681331    715.391648   534.306194   135.617708    5.029151   \n",
       "min        0.000000      0.000000     0.000000     0.000000    0.000000   \n",
       "25%      450.000000    180.000000    90.800000    50.120000    2.370000   \n",
       "50%      685.420000    270.000000   161.650000    73.850000    3.850000   \n",
       "75%     1053.420000    460.980000   265.510000   125.810000    6.320000   \n",
       "max    11949.330000  11500.000000  9593.480000  1748.130000   76.630000   \n",
       "\n",
       "             f_46          f_47        f_48        f_49      target  \n",
       "count  937.000000    937.000000  937.000000  937.000000  937.000000  \n",
       "mean     0.128068   7985.718004   61.694386    8.119723    0.043757  \n",
       "std      0.334344   6854.504915   10.412807    2.908895    0.204662  \n",
       "min      0.000000   2051.500000   35.950000    5.810000    0.000000  \n",
       "25%      0.000000   3760.570000   65.720000    6.340000    0.000000  \n",
       "50%      0.000000   5509.430000   65.930000    7.220000    0.000000  \n",
       "75%      0.000000   9521.930000   66.130000    7.840000    0.000000  \n",
       "max      1.000000  55128.460000   66.450000   15.440000    1.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db05c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "111fb19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_1       0\n",
       "f_2       0\n",
       "f_3       0\n",
       "f_4       0\n",
       "f_5       0\n",
       "f_6       0\n",
       "f_7       0\n",
       "f_8       0\n",
       "f_9       0\n",
       "f_10      0\n",
       "f_11      0\n",
       "f_12      0\n",
       "f_13      0\n",
       "f_14      0\n",
       "f_15      0\n",
       "f_16      0\n",
       "f_17      0\n",
       "f_18      0\n",
       "f_19      0\n",
       "f_20      0\n",
       "f_21      0\n",
       "f_22      0\n",
       "f_23      0\n",
       "f_24      0\n",
       "f_25      0\n",
       "f_26      0\n",
       "f_27      0\n",
       "f_28      0\n",
       "f_29      0\n",
       "f_30      0\n",
       "f_31      0\n",
       "f_32      0\n",
       "f_33      0\n",
       "f_34      0\n",
       "f_35      0\n",
       "f_36      0\n",
       "f_37      0\n",
       "f_38      0\n",
       "f_39      0\n",
       "f_40      0\n",
       "f_41      0\n",
       "f_42      0\n",
       "f_43      0\n",
       "f_44      0\n",
       "f_45      0\n",
       "f_46      0\n",
       "f_47      0\n",
       "f_48      0\n",
       "f_49      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1642b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f_1', 'f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7', 'f_8', 'f_9', 'f_10',\n",
       "       'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17', 'f_18', 'f_19',\n",
       "       'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_27', 'f_28',\n",
       "       'f_29', 'f_30', 'f_31', 'f_32', 'f_33', 'f_34', 'f_35', 'f_36', 'f_37',\n",
       "       'f_38', 'f_39', 'f_40', 'f_41', 'f_42', 'f_43', 'f_44', 'f_45', 'f_46',\n",
       "       'f_47', 'f_48', 'f_49', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8dafa",
   "metadata": {},
   "source": [
    "### ● Non-Spill: negative case, or majority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7463e076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0         896\n",
       "1          41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_count = data[['target']].value_counts()\n",
    "target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea704053",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority_class is  0\n",
      "Negative_class is  896\n"
     ]
    }
   ],
   "source": [
    "target_variable = 'target'\n",
    "class_count = data[target_variable].value_counts()\n",
    "majority_class = class_count.idxmax()\n",
    "negative_class = class_count[majority_class]\n",
    "\n",
    "print('Majority_class is ' , majority_class)\n",
    "print('Negative_class is ' , negative_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567ff8a",
   "metadata": {},
   "source": [
    "### ● Oil Spill: positive case, or minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b7b5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority_class is  1\n",
      "Negative_class is  41\n"
     ]
    }
   ],
   "source": [
    "target_variable = 'target'\n",
    "class_count = data[target_variable].value_counts()\n",
    "minority_class = class_count.idxmin()\n",
    "positive_case = class_count[minority_class]\n",
    "\n",
    "print('Minority_class is ' , minority_class)\n",
    "print('Negative_class is ' , positive_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c513509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.155581</td>\n",
       "      <td>0.172017</td>\n",
       "      <td>-0.104116</td>\n",
       "      <td>-0.017025</td>\n",
       "      <td>-0.169533</td>\n",
       "      <td>-0.037412</td>\n",
       "      <td>-0.204983</td>\n",
       "      <td>-0.244551</td>\n",
       "      <td>-0.214447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286190</td>\n",
       "      <td>-0.167466</td>\n",
       "      <td>-0.156916</td>\n",
       "      <td>-0.141792</td>\n",
       "      <td>-0.139478</td>\n",
       "      <td>-0.163693</td>\n",
       "      <td>-0.202983</td>\n",
       "      <td>0.294422</td>\n",
       "      <td>-0.253698</td>\n",
       "      <td>-0.180531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_2</th>\n",
       "      <td>-0.155581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058390</td>\n",
       "      <td>0.052638</td>\n",
       "      <td>-0.036870</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>-0.136761</td>\n",
       "      <td>-0.016822</td>\n",
       "      <td>0.829978</td>\n",
       "      <td>0.128465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555154</td>\n",
       "      <td>0.777807</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.716496</td>\n",
       "      <td>-0.080879</td>\n",
       "      <td>-0.048315</td>\n",
       "      <td>0.118792</td>\n",
       "      <td>-0.128222</td>\n",
       "      <td>0.139417</td>\n",
       "      <td>0.034128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_3</th>\n",
       "      <td>0.172017</td>\n",
       "      <td>0.058390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.549510</td>\n",
       "      <td>-0.082764</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>-0.627934</td>\n",
       "      <td>-0.349541</td>\n",
       "      <td>0.158686</td>\n",
       "      <td>0.073794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186920</td>\n",
       "      <td>0.178287</td>\n",
       "      <td>0.129653</td>\n",
       "      <td>0.176883</td>\n",
       "      <td>-0.088310</td>\n",
       "      <td>-0.182458</td>\n",
       "      <td>-0.022098</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>-0.035221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_4</th>\n",
       "      <td>-0.104116</td>\n",
       "      <td>0.052638</td>\n",
       "      <td>0.549510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048847</td>\n",
       "      <td>0.024693</td>\n",
       "      <td>-0.546205</td>\n",
       "      <td>-0.222063</td>\n",
       "      <td>0.097683</td>\n",
       "      <td>0.202167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046934</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>-0.220461</td>\n",
       "      <td>-0.204776</td>\n",
       "      <td>0.106758</td>\n",
       "      <td>-0.394081</td>\n",
       "      <td>0.476127</td>\n",
       "      <td>-0.050489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_5</th>\n",
       "      <td>-0.017025</td>\n",
       "      <td>-0.036870</td>\n",
       "      <td>-0.082764</td>\n",
       "      <td>0.048847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028431</td>\n",
       "      <td>0.059128</td>\n",
       "      <td>0.123814</td>\n",
       "      <td>-0.047879</td>\n",
       "      <td>0.098573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066930</td>\n",
       "      <td>-0.014877</td>\n",
       "      <td>-0.013742</td>\n",
       "      <td>-0.012346</td>\n",
       "      <td>-0.076695</td>\n",
       "      <td>-0.080136</td>\n",
       "      <td>0.070070</td>\n",
       "      <td>-0.135294</td>\n",
       "      <td>0.116896</td>\n",
       "      <td>-0.078598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f_1       f_2       f_3       f_4       f_5       f_6       f_7  \\\n",
       "f_1  1.000000 -0.155581  0.172017 -0.104116 -0.017025 -0.169533 -0.037412   \n",
       "f_2 -0.155581  1.000000  0.058390  0.052638 -0.036870  0.953947 -0.136761   \n",
       "f_3  0.172017  0.058390  1.000000  0.549510 -0.082764  0.050795 -0.627934   \n",
       "f_4 -0.104116  0.052638  0.549510  1.000000  0.048847  0.024693 -0.546205   \n",
       "f_5 -0.017025 -0.036870 -0.082764  0.048847  1.000000 -0.028431  0.059128   \n",
       "\n",
       "          f_8       f_9      f_10  ...      f_41      f_42      f_43  \\\n",
       "f_1 -0.204983 -0.244551 -0.214447  ... -0.286190 -0.167466 -0.156916   \n",
       "f_2 -0.016822  0.829978  0.128465  ...  0.555154  0.777807  0.800939   \n",
       "f_3 -0.349541  0.158686  0.073794  ...  0.186920  0.178287  0.129653   \n",
       "f_4 -0.222063  0.097683  0.202167  ... -0.046934  0.032402  0.022234   \n",
       "f_5  0.123814 -0.047879  0.098573  ... -0.066930 -0.014877 -0.013742   \n",
       "\n",
       "         f_44      f_45      f_46      f_47      f_48      f_49    target  \n",
       "f_1 -0.141792 -0.139478 -0.163693 -0.202983  0.294422 -0.253698 -0.180531  \n",
       "f_2  0.716496 -0.080879 -0.048315  0.118792 -0.128222  0.139417  0.034128  \n",
       "f_3  0.176883 -0.088310 -0.182458 -0.022098  0.048291  0.162600 -0.035221  \n",
       "f_4  0.000664 -0.220461 -0.204776  0.106758 -0.394081  0.476127 -0.050489  \n",
       "f_5 -0.012346 -0.076695 -0.080136  0.070070 -0.135294  0.116896 -0.078598  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49fd1f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_1    f_2      f_3     f_4  f_5       f_6    f_7   f_8      f_9  f_10  \\\n",
       "0    1   2558  1506.09  456.63   90   6395000  40.88  7.89  29780.0  0.19   \n",
       "1    2  22325    79.11  841.03  180  55812500  51.11  1.21  61900.0  0.02   \n",
       "2    3    115  1449.85  608.43   88    287500  40.42  7.34   3340.0  0.18   \n",
       "3    4   1201  1562.53  295.65   66   3002500  42.40  7.97  18030.0  0.19   \n",
       "4    5    312   950.27  440.86   37    780000  41.43  7.03   3350.0  0.17   \n",
       "\n",
       "   ...     f_41      f_42     f_43     f_44   f_45  f_46      f_47   f_48  \\\n",
       "0  ...  2850.00   1000.00   763.16   135.46   3.73     0  33243.19  65.74   \n",
       "1  ...  5750.00  11500.00  9593.48  1648.80   0.60     0  51572.04  65.73   \n",
       "2  ...  1400.00    250.00   150.00    45.13   9.33     1  31692.84  65.81   \n",
       "3  ...  6041.52    761.58   453.21   144.97  13.33     1  37696.21  65.67   \n",
       "4  ...  1320.04    710.63   512.54   109.16   2.58     0  29038.17  65.66   \n",
       "\n",
       "   f_49  target  \n",
       "0  7.95       1  \n",
       "1  6.26       0  \n",
       "2  7.84       1  \n",
       "3  8.07       1  \n",
       "4  7.35       0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data.copy()\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01ee00de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a29f8",
   "metadata": {},
   "source": [
    "#### This data set have given target variable.\n",
    "In this data set i use supervise learnig and the target variable is between 0 and 1 .such that we use to clasification.<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41713d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data1.drop('target', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33d07e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f50b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac03d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(749, 49)\n",
      "(188, 49)\n",
      "(749,)\n",
      "(188,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aff97b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3c4dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_eval(ytest,ypred):\n",
    "    cm = confusion_matrix(ytest,ypred)\n",
    "    print(cm)\n",
    "    print('Accuracy Score',accuracy_score(ytest,ypred))\n",
    "    print(classification_report(ytest,ypred,zero_division=0))\n",
    "    \n",
    "def mscore(model):\n",
    "    print('Training Score',model.score(x_train,y_train))  \n",
    "    print('Testing Score',model.score(x_test,y_test))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f6faa",
   "metadata": {},
   "source": [
    "### 1. Build the model from Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be1a751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=80)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=80)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=80)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=80,criterion='gini')\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff61948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 1.0\n",
      "Testing Score 0.973404255319149\n"
     ]
    }
   ],
   "source": [
    "mscore(rf)\n",
    "# data is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8897fa",
   "metadata": {},
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "733b9c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(188,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_rf = rf.predict(x_test)\n",
    "print(ypred_rf)\n",
    "ypred_rf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3ff7b",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ea775f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[179   1]\n",
      " [  3   5]]\n",
      "Accuracy Score 0.9787234042553191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       180\n",
      "           1       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.98       188\n",
      "   macro avg       0.91      0.81      0.85       188\n",
      "weighted avg       0.98      0.98      0.98       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_eval(y_test,ypred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be1a5f",
   "metadata": {},
   "source": [
    "### 2. Build the model from Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e125e1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>...</th>\n",
       "      <th>f_41</th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_1    f_2      f_3     f_4  f_5       f_6    f_7   f_8      f_9  f_10  \\\n",
       "0    1   2558  1506.09  456.63   90   6395000  40.88  7.89  29780.0  0.19   \n",
       "1    2  22325    79.11  841.03  180  55812500  51.11  1.21  61900.0  0.02   \n",
       "2    3    115  1449.85  608.43   88    287500  40.42  7.34   3340.0  0.18   \n",
       "3    4   1201  1562.53  295.65   66   3002500  42.40  7.97  18030.0  0.19   \n",
       "4    5    312   950.27  440.86   37    780000  41.43  7.03   3350.0  0.17   \n",
       "\n",
       "   ...     f_41      f_42     f_43     f_44   f_45  f_46      f_47   f_48  \\\n",
       "0  ...  2850.00   1000.00   763.16   135.46   3.73     0  33243.19  65.74   \n",
       "1  ...  5750.00  11500.00  9593.48  1648.80   0.60     0  51572.04  65.73   \n",
       "2  ...  1400.00    250.00   150.00    45.13   9.33     1  31692.84  65.81   \n",
       "3  ...  6041.52    761.58   453.21   144.97  13.33     1  37696.21  65.67   \n",
       "4  ...  1320.04    710.63   512.54   109.16   2.58     0  29038.17  65.66   \n",
       "\n",
       "   f_49  target  \n",
       "0  7.95       1  \n",
       "1  6.26       0  \n",
       "2  7.84       1  \n",
       "3  8.07       1  \n",
       "4  7.35       0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c824d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "37539da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1 = DecisionTreeClassifier(criterion='gini')\n",
    "dt1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "af7b9ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 1.0\n",
      "Testing Score 0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "mscore(dt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8bf6b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "ypred_dt1 = dt1.predict(x_test)\n",
    "print(ypred_dt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "939efb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175   5]\n",
      " [  3   5]]\n",
      "Accuracy Score 0.9574468085106383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       180\n",
      "           1       0.50      0.62      0.56         8\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.74      0.80      0.77       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_eval(y_test,ypred_dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137065f",
   "metadata": {},
   "source": [
    "### 3. Build the model LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "db01a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "719ee880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000,solver='liblinear')\n",
    "log_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1eefaa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 0.9679572763684913\n",
      "Testing Score 0.973404255319149\n"
     ]
    }
   ],
   "source": [
    "mscore(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9c103ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "ypred_logreg = log_reg.predict(x_test)\n",
    "print(ypred_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "725d183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[177   3]\n",
      " [  2   6]]\n",
      "Accuracy Score 0.973404255319149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       180\n",
      "           1       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.97       188\n",
      "   macro avg       0.83      0.87      0.85       188\n",
      "weighted avg       0.98      0.97      0.97       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_eval(y_test,ypred_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "af9d5bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression Model is 0.973404255319149\n",
      "Accuracy of Random Forest Classifier Model is 0.9787234042553191\n",
      "Accuracy of Decision Tree Classifier Model is 0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "acc_log = accuracy_score(y_test,ypred_logreg)\n",
    "acc_randf = accuracy_score(y_test,ypred_rf)\n",
    "acc_dec = accuracy_score(y_test,ypred_dt1)\n",
    "print('Accuracy of LogisticRegression Model is',acc_log)\n",
    "print('Accuracy of Random Forest Classifier Model is',acc_randf)\n",
    "print('Accuracy of Decision Tree Classifier Model is',acc_dec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
